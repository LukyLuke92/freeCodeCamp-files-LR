{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukyLuke92/freeCodeCamp-files-LR/blob/main/MachineLearningWithPython/NeuralNetworkSMSTextClassifier/fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "#!pip install --upgrade tensorflow\n",
        "#!pip install --upgrade keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ],
      "metadata": {
        "id": "clEDWUnVrva6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data as dataframes\n",
        "train_data = pd.read_csv(train_file_path,sep='\\t',header=None)\n",
        "test_data = pd.read_csv(test_file_path,sep='\\t',header=None)\n",
        "# Rename the columns to label and text\n",
        "train_data.rename(columns={0: 'label',1: 'text'},inplace=True)\n",
        "test_data.rename(columns={0: 'label',1: 'text'},inplace=True)\n",
        "# Convert back and forth between ham and spam labels (ham=0, spam=1)\n",
        "hamspam_to_idx = {'ham': 0, 'spam': 1}\n",
        "idx_to_hamspam = ['ham','spam']\n",
        "# Apply hamspam_to_idx to both datasets and pop them off into label dataframes\n",
        "train_labels = train_data.pop('label').apply(lambda x: hamspam_to_idx[x])\n",
        "test_labels = test_data.pop('label').apply(lambda x: hamspam_to_idx[x])"
      ],
      "metadata": {
        "id": "tg7yAwznrw3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of words (text separated by spaces) in each text\n",
        "text_words = train_data['text'].apply(lambda x: x.split(' ')).str.len().value_counts()\n",
        "plt.bar(text_words.index,height=text_words)\n",
        "# Find the maximum number of words in a text\n",
        "# Note that this is cast as an int, since it is originally a numpy int64, which\n",
        "#  appears to be incompatible as an input to the textvectorization layer\n",
        "max_text_len = int(train_data['text'].apply(lambda x: x.split(' ')).str.len().max())\n",
        "print(max_text_len)"
      ],
      "metadata": {
        "id": "n0B8yrMlZa3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an input layer (object?)\n",
        "input_layer = keras.Input(\n",
        "    shape=(1,),\n",
        "    dtype='string'\n",
        ")\n",
        "\n",
        "# Create a layer that will vectorize the text\n",
        "text_vectorizer = keras.layers.TextVectorization(\n",
        "    split='whitespace',\n",
        "    output_sequence_length=max_text_len\n",
        ")\n",
        "text_vectorizer.adapt(train_data)\n",
        "\n",
        "vocab_size = len(text_vectorizer.get_vocabulary())\n",
        "\n",
        "# Create a layer for embedding the vectorized text\n",
        "embedding_dim = 256\n",
        "embedding_layer = keras.layers.Embedding(vocab_size,\n",
        "                                         embedding_dim)"
      ],
      "metadata": {
        "id": "pc6a3P0BsM0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "# Use a global average pooling 1D layer to average the embedding values across\n",
        "#  all words found in the text\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    input_layer,\n",
        "    text_vectorizer,\n",
        "    embedding_layer,\n",
        "    keras.layers.GlobalAveragePooling1D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256,\n",
        "                      activation='tanh'),\n",
        "    keras.layers.Dense(128,\n",
        "                      activation='relu'),\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "IQxst12PsgNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H4Amq-ODuuDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Note that using GPU speeds this up by > 50 x (~10 seconds per epoch with GPU,\n",
        "#  ~10 minutes per epoch without)\n",
        "# Adding class_weight dictionary, since spam messages are significantly under-\n",
        "#  represented in the dataset\n",
        "\n",
        "history = model.fit(x=train_data,\n",
        "          y=train_labels,\n",
        "          epochs=25,\n",
        "          validation_split=0.2,\n",
        "          class_weight={0: 1,\n",
        "                        1: 25}\n",
        "          )"
      ],
      "metadata": {
        "id": "6OWAeX4puvZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy values over time\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "fyAitRhDe4xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=test_data,\n",
        "               y=test_labels)"
      ],
      "metadata": {
        "id": "kzuZq76_faOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  model_out = model.predict(np.expand_dims(pred_text,axis=0))\n",
        "  prediction = [model_out[0][0], 'ham' if model_out[0][0] < 0.5 else 'spam']\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"you have won £1000 cash! call to claim your prize.\"\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "b6fli2WLfc82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "      print(f'incorrectly classified \"{msg}\"')\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ],
      "metadata": {
        "id": "qDwewwBvfvXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### DO NOT USE CODE BELOW ######\n",
        "# Code below is first attempt, which split each message into individual\n",
        "#  characters, embedded the resulting list, and used an LSTM - while this\n",
        "#  performed very well on the test (>97% accuracy), it still fails to catch the\n",
        "#  test case \"our new mobile video service is live. just install on your phone\n",
        "#  to start watching.\" - it is also much more computationally expensive\n",
        "# Because this is very subtly spam, I think the model will need to look for\n",
        "#  specific words, such as 'service' and 'install' - because of that, the code\n",
        "#  above uses a text vectorization layer to instead split by spaces"
      ],
      "metadata": {
        "id": "3P5-MujfrByp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "# Import and clean/wrangle the data\n",
        "# Import the data as dataframes\n",
        "train_data = pd.read_csv(train_file_path,sep='\\t',header=None)\n",
        "test_data = pd.read_csv(test_file_path,sep='\\t',header=None)\n",
        "# Rename the columns to label and text\n",
        "train_data.rename(columns={0: 'label',1: 'text'},inplace=True)\n",
        "test_data.rename(columns={0: 'label',1: 'text'},inplace=True)\n",
        "# Plot distributions of text lengths in train_data and test_data\n",
        "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,9))\n",
        "ax1.bar(train_data['text'].str.len().value_counts().index,height=train_data['text'].str.len().value_counts())\n",
        "ax2.bar(test_data['text'].str.len().value_counts().index,height=test_data['text'].str.len().value_counts())\n",
        "# Get percentage of texts with length > max_length\n",
        "max_length = 200\n",
        "num_gr_max_train = train_data['text'].str.len().value_counts()[train_data['text'].str.len().value_counts().index > max_length].sum()\n",
        "num_gr_max_test = test_data['text'].str.len().value_counts()[test_data['text'].str.len().value_counts().index > max_length].sum()\n",
        "print(f'frac greater than {max_length} in train_data',num_gr_max_train/train_data.shape[0])\n",
        "print(f'frac greater than {max_length} in test_data',num_gr_max_test/test_data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It looks like only ~2% of texts are longer than 200 characters\n",
        "# In addition, none of the texts in the test case are longer than 200\n",
        "# Therefore, truncate texts to a max length of 200 - also, pad texts that are\n",
        "#  less than 200, so that they are all the same length (using ljust)\n",
        "# Do this using a function - any text that you'll want to make predictions on\n",
        "#  later will need to be formatted using the same function\n",
        "def trunc_or_pad(msg):\n",
        "  if len(msg) > 200:\n",
        "    return msg[0:200]\n",
        "  else:\n",
        "    return msg.ljust(200)"
      ],
      "metadata": {
        "id": "euyeV2ErKhB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your vocabulary by finding all unique characters in both datasets\n",
        "vocab = sorted(set(train_data['text'].sum() + test_data['text'].sum()))\n",
        "vocab_size = len(vocab)\n",
        "# Create a dictionary that contains char as key and index as val\n",
        "char_to_idx = { u: i for i, u in enumerate(vocab) }\n",
        "# Create an array that has char corresponding to each index\n",
        "idx_to_char = np.array(vocab)\n",
        "# Do the same for ham and spam labels (ham=0, spam=1)\n",
        "hamspam_to_idx = {'ham': 0, 'spam': 1}\n",
        "idx_to_hamspam = ['ham','spam']"
      ],
      "metadata": {
        "id": "pBgWEiHUNqUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that converts an input string into an input vector that can\n",
        "#  be fed into the input (embedding) layer of the model\n",
        "def string_to_input(text):\n",
        "  padded_text = trunc_or_pad(text)\n",
        "  return np.array([char_to_idx[x] for x in list(padded_text)])"
      ],
      "metadata": {
        "id": "0pMoBDzGPWaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now apply string_to_input to both datasets\n",
        "train_data['text'] = train_data['text'].apply(lambda x: string_to_input(x))\n",
        "test_data['text'] = test_data['text'].apply(lambda x: string_to_input(x))"
      ],
      "metadata": {
        "id": "93DXbdjnS2rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now apply hamspam_to_idx to labels and pop them off into a new series\n",
        "train_labels = train_data.pop('label').apply(lambda x: hamspam_to_idx[x])\n",
        "test_labels = test_data.pop('label').apply(lambda x: hamspam_to_idx[x])"
      ],
      "metadata": {
        "id": "yxqwfzrKTZ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, create a new dataframe that has each element of the list in 'text'\n",
        "#  in a separate column\n",
        "# I do not think that this is the optimal way to do this, but it should work\n",
        "for i in range(200):\n",
        "  train_data[i] = train_data['text'].apply(lambda x: x[i])\n",
        "  test_data[i] = test_data['text'].apply(lambda x: x[i])\n",
        "train_data = train_data.drop(columns='text')\n",
        "test_data = test_data.drop(columns='text')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SQrAc10flykP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "# The first layer will be an embedding layer, followed by a layer of LSTM nodes,\n",
        "#  then at least one hidden dense layer, and finally a dense layer consisting of\n",
        "#  two output nodes with a 'softmax' activation function\n",
        "\n",
        "# Dimension of the dense embedding\n",
        "embedding_dim = 256\n",
        "RNN_units = 1024\n",
        "batch_size = 200\n",
        "timesteps = 50\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, RNN_units, batch_size):\n",
        "  model = keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,\n",
        "                            embedding_dim,\n",
        "                            input_shape=(batch_size,)),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.LSTM(RNN_units,\n",
        "                        return_sequences=True,\n",
        "                        recurrent_initializer='glorot_uniform',\n",
        "                        batch_input_shape=(batch_size, timesteps, embedding_dim)), # By default uses tanh activation function\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64,activation='relu'),\n",
        "      tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, RNN_units, batch_size)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "a06KKXyVT82_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UVt7oVY7hlof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Note that using GPU speeds this up by > 50 x (~10 seconds per epoch with GPU,\n",
        "#  ~10 minutes per epoch without)\n",
        "# Adding class_weight dictionary, since spam messages are significantly under-\n",
        "#  represented in the dataset\n",
        "history = model.fit(x=train_data,\n",
        "          y=train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=25,\n",
        "          validation_split=0.2,\n",
        "          class_weight={0: 1,\n",
        "                        1: 25}\n",
        "          )"
      ],
      "metadata": {
        "id": "MS4rEeExkO5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "OC8Qnyi8kLff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=test_data,\n",
        "               y=test_labels,\n",
        "               batch_size=batch_size)"
      ],
      "metadata": {
        "id": "x6hsu4sOloF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  padded_pred_text = np.array(string_to_input(pred_text))\n",
        "  model_out = model.predict(np.expand_dims(padded_pred_text,axis=0))\n",
        "  prediction = [model_out[0][0], 'ham' if model_out[0][0] < 0.5 else 'spam']\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"you have won £1000 cash! call to claim your prize.\"\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "      print(f'incorrectly classified \"{msg}\"')\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {},
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}